{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiyjNk3wlZ2fN6um92eXQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ander002/DeepLearning/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmprjByX7Ulj"
      },
      "source": [
        "### 入门pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCS15ZiU7dA6"
      },
      "source": [
        "## 基本操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZL3p5EX2o31",
        "outputId": "426333e5-26aa-4882-a6a8-94b1c1a28bcb"
      },
      "source": [
        "import torch\n",
        "x = torch.arange(12) #创建的一个行向量[0,12)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_njIGey3D0J",
        "outputId": "1a636de6-dd0d-47a0-9083-7f170882dc9e"
      },
      "source": [
        "x.shape #访问张量的形状"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-NBhOcV3Sjd",
        "outputId": "9cc7947a-3207-4b2c-fb52-8699a65d0fba"
      },
      "source": [
        "x.numel()  #一个张量中元素的总数"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMTGl4jV3gp3",
        "outputId": "a341c622-ce82-41a9-b88c-7ac8131cef34"
      },
      "source": [
        "X = x.reshape(3, 4)  #改变形状，不改变元素数量和值\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjbqKVf64GSj",
        "outputId": "e4f951ec-8a35-4574-9113-3bf352298931"
      },
      "source": [
        "torch.zeros(2, 3, 4) #生成全0矩阵 torch.ones(2, 3, 4,2)这是全1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlsSuOMR4vtN",
        "outputId": "176531ef-a372-49c2-b9e8-9bd8dc5fd59c"
      },
      "source": [
        "torch.randn(3, 4) #随机创建一个（3，4）的张量，其中每个元素都从均值0、标准差为1的标准高斯分布中随机取样"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3303, -0.0402,  0.3889, -0.5177],\n",
              "        [ 0.0255,  0.0956, -1.1163, -0.6623],\n",
              "        [-0.8355, -0.9201, -0.8355, -0.9374]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQHgCq55rg2",
        "outputId": "601fda29-ec22-4a52-a450-b4aba5bcc42f"
      },
      "source": [
        "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])  #提供python列表（嵌套列表）来为张量中的元素赋值，这里外层的列表对应0轴，内层对应1轴"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcYRiYaP7rSR"
      },
      "source": [
        "## 运算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP8kL0-37ulA",
        "outputId": "d8a72098-693c-4aea-a659-1cffdac4bc39"
      },
      "source": [
        "x = torch.tensor([1.0, 2, 4, 8])\n",
        "y = torch.tensor([2, 2, 2, 2])\n",
        "x + y,x - y, x * y,x / y,x ** y,torch.exp(x) # 元素对应运算，** 是求幂运算,"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3.,  4.,  6., 10.]),\n",
              " tensor([-1.,  0.,  2.,  6.]),\n",
              " tensor([ 2.,  4.,  8., 16.]),\n",
              " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
              " tensor([ 1.,  4., 16., 64.]),\n",
              " tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efOmmsOh9F2G",
        "outputId": "a0929457-a501-4718-9d22-ea62710a89a6"
      },
      "source": [
        "import torch\n",
        "X = torch.arange(12,dtype = torch.float32).reshape(3,4)  #reshape((3,4))?????\n",
        "Y = torch.tensor([[2.0, 1, 4, 3],[1, 2, 3, 4],[4, 3, 2, 1]])\n",
        "torch.cat((X,Y),dim=0), torch.cat((X,Y),dim=1) #把多个张量连接在一起，dim=0，按0轴链接就是按行堆积，行数增加，dim=1，按1轴链接就是按列拼接，列数增加"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [ 2.,  1.,  4.,  3.],\n",
              "         [ 1.,  2.,  3.,  4.],\n",
              "         [ 4.,  3.,  2.,  1.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
              "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBBjdhzw_Cz_",
        "outputId": "adb10c31-9de4-49fe-cc48-626d4c948222"
      },
      "source": [
        "X == Y  #通过逻辑运算符构建张量"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hGVZk68_j9Q",
        "outputId": "c154e7db-3479-4bd1-f1b5-0925f83fa376"
      },
      "source": [
        "X.sum() #对张量中所有元素进行求和，产生一个元素的张量"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIotxe3R_5Iw",
        "outputId": "24c33c97-850f-4eef-8fd4-77e1f2bbf989"
      },
      "source": [
        "a = torch.arange(3).reshape((3,1))\n",
        "b = torch.arange(2).reshape((1,2)) #广播机制\n",
        "a, b "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]), tensor([[0, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AkiIGQ3BHBE",
        "outputId": "9a4f1f3a-b128-4c20-98fd-d7de353e5a09"
      },
      "source": [
        "a + b  #形状不匹配的矩阵相加，广播机制将两个矩阵广播为一个更大的3x2矩阵，矩阵a将复制列，矩阵b将复制行"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHIgWFwhPokS",
        "outputId": "6cd6fa97-c8f7-4488-f2e6-e5e55f65b74d"
      },
      "source": [
        "X[-1],X[1:3] #张量可以通过索引访问，与python一样，第一个元素的索引是0，负号表示从列表尾部相对应的元素，-1代表最后一行元素，[1:3]的意思是选择第二个和第三个元素，这里是指第二行和第三行。"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]), tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z8V8_XMRAi_",
        "outputId": "f15a9132-524a-4d4c-b1f2-7e35fad2aae4"
      },
      "source": [
        "X[1, 2] = 9    #修改指定元素\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  9.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCH1nj8bRSdU",
        "outputId": "19be73eb-3b88-4b0d-840c-c4074a6b03e0"
      },
      "source": [
        "X[0:2, :] = 12   #批量修改元素值，这里指的是第[0,2)行，和所有列修改为12\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12., 12., 12., 12.],\n",
              "        [12., 12., 12., 12.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOg0HtLbR4sG",
        "outputId": "d2b9a7d5-20d5-42ec-ece6-7277b054e664"
      },
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before  #这表示python是先计算Y+X然后把Y指向新地址，这样做有两个弊端，第一，我们不想让他经常分配新内存，第二，分配新内存后，旧内存依然是我们旧的参数，很有可能某次调参的时候就会指向无用的旧内存"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxvSDr_9Txg_",
        "outputId": "2731f5e5-ba3b-4434-d1ee-d5623b69bbd9"
      },
      "source": [
        "Z = torch.zeros_like(Y)\n",
        "print(f'id(Z):{id(Z)}')\n",
        "Z[:] = X + Y          #执行原地操作非常简单，我们可以使用切片表示法，将操作的结果分配给先前分配的数组。\n",
        "print(f'id(Z):{id(Z)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id(Z):140137726682608\n",
            "id(Z):140137726682608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5179Byv_V0Wp",
        "outputId": "2c1789a1-d5b5-4250-f111-7c6a34d51ac7"
      },
      "source": [
        "before = id(X)\n",
        "X += Y   #如果之后没有用X的话可以X[:] = X+Y或者X+=Y来减少内存开销\n",
        "id(X) == before"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VIl9HtzWQ_Q",
        "outputId": "14ddecb4-cbab-4305-d67a-6eb62a8b892b"
      },
      "source": [
        "A = X.numpy()    #转换python对象\n",
        "B = torch.tensor(A)\n",
        "type(A),type(B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvVb_0NvX7DP",
        "outputId": "8d54c5ed-3c5e-49c3-b2f8-0b2daa057ca8"
      },
      "source": [
        "a = torch.tensor([3.5])    #将大小为1的张量转换为python 标量，可以用item。\n",
        "a,a.item(),float(a),int(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9i4XrX3Y4an"
      },
      "source": [
        "## 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHUYyfuQY7ZH"
      },
      "source": [
        "import os \n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)  #创建人工数据集\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv') \n",
        "with open(data_file, 'w') as f: \n",
        "  f.write('NumRooms,Alley,Price\\n') # 列名 \n",
        "  f.write('NA,Pave,127500\\n') # 每⾏表⽰⼀个数据样本 \n",
        "  f.write('2,NA,106000\\n') \n",
        "  f.write('4,NA,178100\\n') \n",
        "  f.write('NA,NA,140000\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "RWH44AO3Iu40",
        "outputId": "d729e41e-03ff-44be-9975-cc5bdb0157f4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)  #读取数据，其中有许多缺失值，我们要处理缺失值，有插值和删除两种解决，我们用插值\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NumRooms</th>\n",
              "      <th>Alley</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pave</td>\n",
              "      <td>127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>178100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NumRooms Alley   Price\n",
              "0       NaN  Pave  127500\n",
              "1       2.0   NaN  106000\n",
              "2       4.0   NaN  178100\n",
              "3       NaN   NaN  140000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-14QErfJfnW",
        "outputId": "87328138-b307-4dc1-ed42-9eb5fb0d6e35"
      },
      "source": [
        "inputs,outputs = data.iloc[:,0:2],data.iloc[:,2]     #iloc是位置索引，inputs是data的前两列，outputs是data的最后一列\n",
        "inputs = inputs.fillna(inputs.mean())    #fillna函数是若存在缺失值，用参数代替，这里我们用平均数代替\n",
        "print(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHNc047qNYRv",
        "outputId": "c7f39b43-a757-4015-e773-87636cdda72d"
      },
      "source": [
        "inputs = pd.get_dummies(inputs,dummy_na=True)    #由于我们Alley的值只有NaN和Pave两种，所以我们可以吧Alley分为两列Alley_Pave和Alley_nan\n",
        "print(inputs)                                    #其中Alley值为Pave，则Alley_Pave的值为1，反之为0，Alley_nan同理。"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0       3.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           0          1\n",
            "3       3.0           0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ednZNVO42g",
        "outputId": "1332d9e4-5efa-42d9-8b4e-40049f008106"
      },
      "source": [
        "import torch\n",
        "\n",
        "X,y = torch.tensor(inputs.values),torch.tensor(outputs.values)     #将inputs和outputs转换为张量，\n",
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 0., 1.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W44YdtuLPnlx"
      },
      "source": [
        "### 练习"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN6jrtk0QhYr"
      },
      "source": [
        "#### 创建包含更多行和列的原始数据集\n",
        "1. 删除缺失值最多的列\n",
        "2. 将预处理数据集转换为张量格式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGzlUMB0PtuR"
      },
      "source": [
        "import os \n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)  #创建人工数据集\n",
        "data_files = os.path.join('..', 'data', 'houses_tiny.csv') \n",
        "with open(data_files, 'w') as f: \n",
        "  f.write('NumRooms,Alley,Price\\n') # 列名 \n",
        "  f.write('NA,Pave,127500\\n') # 每⾏表⽰⼀个数据样本 \n",
        "  f.write('2,NA,106000\\n') \n",
        "  f.write('4,NA,178100\\n') \n",
        "  f.write('NA,NA,140000\\n')\n",
        "  f.write('NA,Pave,143430\\n')\n",
        "  f.write('6,NA,190000\\n')\n",
        "  f.write('3,NA,150000\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "JS6LNPxNQgKh",
        "outputId": "8051d775-6fec-4fd8-9052-29e3f7d70711"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_files)  #读取数据，其中有许多缺失值，我们要处理缺失值，有插值和删除两种解决，在这里我们用删除\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NumRooms</th>\n",
              "      <th>Alley</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pave</td>\n",
              "      <td>127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>178100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pave</td>\n",
              "      <td>143430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NumRooms Alley   Price\n",
              "0       NaN  Pave  127500\n",
              "1       2.0   NaN  106000\n",
              "2       4.0   NaN  178100\n",
              "3       NaN   NaN  140000\n",
              "4       NaN  Pave  143430\n",
              "5       6.0   NaN  190000\n",
              "6       3.0   NaN  150000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdHh-gn9RRwe",
        "outputId": "15f856c3-a72e-4e1b-ffa8-62e7c75a3de9"
      },
      "source": [
        "inputs,outputs = data.iloc[:,0:2],data.iloc[:,2]\n",
        "\n",
        "inputs = inputs.dropna(axis=1,thresh=(inputs.count().min()+1))   #dropna函数，其中axis=1是删除有缺失值的列，thresh参数是保留至少有n个非NaN数据的行/列\n",
        "num = inputs.count() # count函数计算非nan元素的数量\n",
        "inputs = inputs.fillna(inputs.mean())\n",
        "inputs,outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   NumRooms\n",
              " 0      3.75\n",
              " 1      2.00\n",
              " 2      4.00\n",
              " 3      3.75\n",
              " 4      3.75\n",
              " 5      6.00\n",
              " 6      3.00, 0    127500\n",
              " 1    106000\n",
              " 2    178100\n",
              " 3    140000\n",
              " 4    143430\n",
              " 5    190000\n",
              " 6    150000\n",
              " Name: Price, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21T0VqkOXOup",
        "outputId": "12e5cca4-553f-4e7e-db63-241a02b8574f"
      },
      "source": [
        "import torch\n",
        "W,z = torch.tensor(inputs.values),torch.tensor(outputs.values)  #转换为张量\n",
        "W,z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3.7500],\n",
              "         [2.0000],\n",
              "         [4.0000],\n",
              "         [3.7500],\n",
              "         [3.7500],\n",
              "         [6.0000],\n",
              "         [3.0000]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000, 143430, 190000, 150000]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rotFaSfdPK0"
      },
      "source": [
        "# 线性代数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQJOGtMsdTNk",
        "outputId": "684a7d69-3a1b-427f-b5e2-4aa1176371ac"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([3.0])  #标量用只有一个元素的张量表示\n",
        "y = torch.tensor([2.0])\n",
        "\n",
        "x + y,x * y,x / y,x ** y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwMPZkmreC0x",
        "outputId": "806ed91f-17b0-486a-c2ca-546fafefa52c"
      },
      "source": [
        "x = torch.arange(4)  #我们用一维张量处理向量，问题如何区分行向量或列向量？\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XCPgL5GefQH",
        "outputId": "dc7df08f-00c6-423b-b689-e91ebcd2b65a"
      },
      "source": [
        "l = x.reshape(4, 1)  #列向量\n",
        "h = x.reshape(1,4)   #行向量\n",
        "l,h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2],\n",
              "         [3]]), tensor([[0, 1, 2, 3]]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rydSm1H3gixK",
        "outputId": "66aef5d6-4b9f-4603-e03e-80261c5017d5"
      },
      "source": [
        "x[3]  #通过索引访问任一元素"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POlJugupgu70",
        "outputId": "a48e5bd5-c66d-4b1c-c623-b2a60a179def"
      },
      "source": [
        "len(x)  #张量长度\n",
        "x.shape  #张量形状  某个轴的维数就是这个轴的长度"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTfhlP0ihKSG",
        "outputId": "04576543-5fa9-4552-ad3a-e16652f5cb23"
      },
      "source": [
        "A = torch.arange(20).reshape(5,4)  #矩阵\n",
        "A,A.T  #A的转置"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11],\n",
              "         [12, 13, 14, 15],\n",
              "         [16, 17, 18, 19]]), tensor([[ 0,  4,  8, 12, 16],\n",
              "         [ 1,  5,  9, 13, 17],\n",
              "         [ 2,  6, 10, 14, 18],\n",
              "         [ 3,  7, 11, 15, 19]]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swi1-tq-hmek",
        "outputId": "000fbc44-aa22-49dc-a83e-2ce7a94c42f5"
      },
      "source": [
        "B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])  #对称矩阵\n",
        "B == B.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97z291b2id5B",
        "outputId": "9590e7c2-c537-4540-98e0-240e580ab4b0"
      },
      "source": [
        "X = torch.arange(24).reshape(2,3,4)  #三维张量\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2LSQKfhpQg5",
        "outputId": "a65a2eb5-5766-4c26-ef46-e9a3fa5b3a1a"
      },
      "source": [
        "A = torch.arange(20,dtype= torch.float32).reshape(5,4)\n",
        "B = A.clone()\n",
        "A,A + B   #形状相同的张量，四则运算后的形状不变"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 0.,  2.,  4.,  6.],\n",
              "         [ 8., 10., 12., 14.],\n",
              "         [16., 18., 20., 22.],\n",
              "         [24., 26., 28., 30.],\n",
              "         [32., 34., 36., 38.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJv-Sq59qIHB",
        "outputId": "c30c357b-c130-4500-befd-16629a6e00c9"
      },
      "source": [
        "A * B #两张量按元素相乘叫哈达玛积，对应元素相乘"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   1.,   4.,   9.],\n",
              "        [ 16.,  25.,  36.,  49.],\n",
              "        [ 64.,  81., 100., 121.],\n",
              "        [144., 169., 196., 225.],\n",
              "        [256., 289., 324., 361.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvqaxQYIqZt1",
        "outputId": "0b284d31-fcbc-4cd5-e96e-d30845c4a3af"
      },
      "source": [
        "a = 2\n",
        "X = torch.arange(24).reshape(2,3,4)  #标量加上或乘上一个张量不会改变形状，其中标量是对张量中每一个元素做运算\n",
        "a + X, (a * X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 2,  3,  4,  5],\n",
              "          [ 6,  7,  8,  9],\n",
              "          [10, 11, 12, 13]],\n",
              " \n",
              "         [[14, 15, 16, 17],\n",
              "          [18, 19, 20, 21],\n",
              "          [22, 23, 24, 25]]]), torch.Size([2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEbI-xMBrNLK",
        "outputId": "70823326-dc0e-4f31-a724-f003a9cb3720"
      },
      "source": [
        "x = torch.arange(4,dtype=torch.float32)  #计算向量元素的总和，用sum（）\n",
        "x, x.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor(6.))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5XWbsWZr0-T",
        "outputId": "2580a3ce-2cad-4a90-8dde-4a78ba59e66a"
      },
      "source": [
        "A.shape,A.sum()  #表示任一张量的形状和元素和。"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), tensor(190.))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvqjWBi5sGG1",
        "outputId": "47e0d9ef-9282-49f7-f82e-04d8e3167dea"
      },
      "source": [
        "A_sum_axis0 = A.sum(axis = 0)    #可以通过指定一个轴来通过求和降低维度，这里指定的是0轴，也就是行，求和降维之后变成向量\n",
        "A_sum_axis0, A_sum_axis0.shape   #也就是说，指定哪一个轴哪一轴就消失。"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJjhmwp3tkvh",
        "outputId": "e81020b8-609b-4a84-ac12-be116739b1ee"
      },
      "source": [
        "A_sum_axis1 = A.sum(axis= 1)\n",
        "A_sum_axis1,A_sum_axis1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ke_NOpKuRif",
        "outputId": "fa6eee4b-5717-4960-e8d6-afe1587826d7"
      },
      "source": [
        "A.sum(axis=[0,1])  #相当于对矩阵所有元素求和。<===>A.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(190.)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgK5-YS6upVe",
        "outputId": "37327670-ca5f-4605-9184-ac580525797e"
      },
      "source": [
        "A.mean(),A.sum()/A.numel()   #求平均值"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9.5000), tensor(9.5000))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf3DqCTavWxX",
        "outputId": "2cf0f46e-95dc-4855-d994-3cbc76050201"
      },
      "source": [
        "A.mean(axis=1),A.sum(axis=1)/A.shape[1]  #指定轴求平均值可以指定轴降低张量维度"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]),\n",
              " tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jtY7JRZo-EHS",
        "outputId": "9b17d360-1435-4562-d7fb-e944da509212"
      },
      "source": [
        "sum_A = A.sum(axis =1,keepdim=True)   #调用函数来计算总和或均值时保持轴数不变。\n",
        "sum_A"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.],\n",
              "        [22.],\n",
              "        [38.],\n",
              "        [54.],\n",
              "        [70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SReDljpG-2Qw",
        "outputId": "9f8eb045-9bb0-4fb6-894a-06b1a8af9ce0"
      },
      "source": [
        "A / sum_A   #sum_A在对行进行求和后仍然保持两个轴，通过广播将A除以sum_A"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
              "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
              "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
              "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
              "        [0.2286, 0.2429, 0.2571, 0.2714]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kmNQKovSARcz",
        "outputId": "36b97601-2b74-4619-9eb0-3c8e7c98d753"
      },
      "source": [
        "A,A.cumsum(axis=0)   #沿某个轴计算A元素的积累总和，比如axis=0按行计算，我们可以调用cumsum函数。不会沿任何轴降低维度。"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  6.,  8., 10.],\n",
              "         [12., 15., 18., 21.],\n",
              "         [24., 28., 32., 36.],\n",
              "         [40., 45., 50., 55.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NnYv4kjFDGH-",
        "outputId": "70ec792b-54db-4853-c6a8-38949f5860ec"
      },
      "source": [
        "y = torch.ones(4,dtype = torch.float32)\n",
        "x,y,torch.dot(x,y)  #点积<x,y>,x的转置乘以y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jY2GHrfbEwG_",
        "outputId": "03191623-7008-4343-c8b8-f0c12722ad9d"
      },
      "source": [
        "torch.sum(x * y)  #按元素乘法，然后进行求和来表示两个向量的点积，"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "If6rIYqnFOg7",
        "outputId": "6f9f2af8-31e6-4a07-a44b-87007de5d4b5"
      },
      "source": [
        "A.shape,x.shape,torch.mv(A,x)      #矩阵——向量积，注意A的列维数（沿轴1的长度）必须与x的维数（长度）相同。"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxn6KP0kG8n2"
      },
      "source": [
        "B = torch.ones(4, 3)\n",
        "torch.mm(A, B)  #矩阵-矩阵乘法，规则5x4   与  4x3 ====>    5x3   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J_JJb1vmINwp",
        "outputId": "0a9b1d1c-3fa4-4ba0-b032-e61b53579772"
      },
      "source": [
        "u = torch.tensor([3.0,-4.0])\n",
        "torch.norm(u)    #L2范数是向量元素平方和的平方根，范数是告诉我们一个向量有多大。"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mFLohAODKv2-",
        "outputId": "9659b091-d95d-4eaa-ffd8-e0d81b6af220"
      },
      "source": [
        "torch.abs(u).sum()   # L1范数受异常值影响较小，绝对值函数和元素求和组合来计算"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sXcu6QO4L9E8",
        "outputId": "f51839db-15a1-403f-9fbd-ec926d49deab"
      },
      "source": [
        "torch.norm(torch.ones(4,9))   #矩阵的Lp范数，矩阵元素平方和的平方根"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0mwXgaWMosq"
      },
      "source": [
        "## 练习\n",
        "1. 证明A的转置的转置是A。\n",
        "2. 给出矩阵A和B，显示转置的和等于和的转置\n",
        "3. 给定任一方矩阵A，A+A的转置总是对称吗？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H1tHerGoMhr9",
        "outputId": "5e4bedfe-5f69-46f9-ea64-1de61939fc1b"
      },
      "source": [
        "A.T.T == A"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jJtZDgwkNzEg",
        "outputId": "03d6be81-e0d6-4386-f10d-49a6cc2b19ff"
      },
      "source": [
        "(A + B).T == A.T + B.T"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True],\n",
              "        [True, True, True, True, True],\n",
              "        [True, True, True, True, True],\n",
              "        [True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DBjhoGHGORUu",
        "outputId": "7fb2603a-c8f9-439a-b1bf-23338c195418"
      },
      "source": [
        "C = torch.arange(36).reshape(6,6)\n",
        "(C + C.T) == (C + C.T).T"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omAqbwSUPJsA"
      },
      "source": [
        "# 微分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkZ-T3uQRw1v",
        "outputId": "b1a2670a-e682-4b74-ac8a-5fdec8f18f78"
      },
      "source": [
        "!pip install d2l"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-0.17.0-py3-none-any.whl (83 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20 kB 38.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 51 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 71 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 81 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 83 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l) (2.23.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l) (3.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (7.6.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter->d2l) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (2.6.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (0.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l) (22.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (1.3.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (4.0.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (21.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2018.9)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (1.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2021.5.30)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j24CH7-wPfg0"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from IPython import display\n",
        "from d2l import torch as d2l\n",
        "\n",
        "def f(x):              #定义一个函数，通过无限逼近来计算某点的导数值。\n",
        "  return 3 * x ** 2 - 4 * x"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZq7Ax6mQjrg",
        "outputId": "7fdc9331-c44e-40e3-a42c-3f47b5cf16ac"
      },
      "source": [
        "def numerical_lim(f, x, h):\n",
        "  return (f(x + h) - f(x)) / h\n",
        "h = 0.1\n",
        "for i in range(5):\n",
        "  print(f'h={h:.5f},numerical_limit={numerical_lim(f, 1, h):.5f}')\n",
        "  h *= 0.1"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h=0.10000,numerical_limit=2.30000\n",
            "h=0.01000,numerical_limit=2.03000\n",
            "h=0.00100,numerical_limit=2.00300\n",
            "h=0.00010,numerical_limit=2.00030\n",
            "h=0.00001,numerical_limit=2.00003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiFvJhSDSFDr"
      },
      "source": [
        "经过逼近x=1这个点，发现numerical_lim在逼近2，通过我们计算也是1点的导数是2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZJVNWW6SkxS"
      },
      "source": [
        "def use_svg_display():\n",
        "  \"\"\"使用svg格式在jupyter中显示绘图\"\"\"\n",
        "  display.set_matplotlib_formats('svg')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSmHzWakS9jZ"
      },
      "source": [
        "def set_figsize(figsize=(3.5,2.5)):\n",
        "  \"\"\"设置matplotlib的图表大小\"\"\"\n",
        "  use_svg_display()\n",
        "  d2l.plt.rcParams['figure.figsize'] = figsize"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qUwwSuTfPA"
      },
      "source": [
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "  \"\"\"设置matplotlib的轴\"\"\"\n",
        "  axes.set_xlabel(xlabel)\n",
        "  axes.set_ylabel(ylabel)\n",
        "  axes.set_xscale(xscale)\n",
        "  axes.set_yscale(yscale)\n",
        "  axes.set_xlim(xlim)\n",
        "  axes.set_ylim(ylim)\n",
        "  if legend:\n",
        "    axes.legend(legend)\n",
        "  axes.grid()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AczUQBtUkLJ"
      },
      "source": [
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "         ylim=None, xscale='linear', yscale='linear',\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
        "    \"\"\"绘制数据点。\"\"\"\n",
        "    if legend is None:\n",
        "        legend = []\n",
        "\n",
        "    set_figsize(figsize)\n",
        "    axes = axes if axes else d2l.plt.gca()\n",
        "\n",
        "    # 如果 `X` 有一个轴，输出True\n",
        "    def has_one_axis(X):\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
        "                and not hasattr(X[0], \"__len__\"))\n",
        "\n",
        "    if has_one_axis(X):\n",
        "        X = [X]\n",
        "    if Y is None:\n",
        "        X, Y = [[]] * len(X), X\n",
        "    elif has_one_axis(Y):\n",
        "        Y = [Y]\n",
        "    if len(X) != len(Y):\n",
        "        X = X * len(Y)\n",
        "    axes.cla()\n",
        "    for x, y, fmt in zip(X, Y, fmts):\n",
        "        if len(x):\n",
        "            axes.plot(x, y, fmt)\n",
        "        else:\n",
        "            axes.plot(y, fmt)\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "ZxWlOJZoU67O",
        "outputId": "9743f580-4257-430a-9e04-59abdb9121de"
      },
      "source": [
        "x = np.arange(0, 3, 0.1)\n",
        "plot(x,[f(x),2 * x - 3],'x','f(x)',legend=['f(x)','Tangent line(x=1)'])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 243.529359 180.65625\" width=\"243.529359pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 243.529359 180.65625 \nL 243.529359 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 143.1 \nL 235.903125 143.1 \nL 235.903125 7.2 \nL 40.603125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 49.480398 143.1 \nL 49.480398 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9822685ec3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.480398\" xlink:href=\"#m9822685ec3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(46.299148 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 110.702968 143.1 \nL 110.702968 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.702968\" xlink:href=\"#m9822685ec3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(107.521718 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 171.925539 143.1 \nL 171.925539 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.925539\" xlink:href=\"#m9822685ec3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(168.744289 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 233.148109 143.1 \nL 233.148109 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"233.148109\" xlink:href=\"#m9822685ec3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(229.966859 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- x -->\n     <defs>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n     </defs>\n     <g transform=\"translate(135.29375 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 40.603125 114.635514 \nL 235.903125 114.635514 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m422ce2e672\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m422ce2e672\" y=\"114.635514\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(27.240625 118.434732)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 40.603125 77.490157 \nL 235.903125 77.490157 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m422ce2e672\" y=\"77.490157\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(27.240625 81.289376)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p7e2f94367c)\" d=\"M 40.603125 40.344801 \nL 235.903125 40.344801 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m422ce2e672\" y=\"40.344801\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 44.14402)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- f(x) -->\n     <defs>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(14.798437 83.771094)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p7e2f94367c)\" d=\"M 49.480398 114.635514 \nL 55.602655 117.38427 \nL 61.724912 119.687282 \nL 67.847169 121.54455 \nL 73.969426 122.956073 \nL 80.091683 123.921853 \nL 86.21394 124.441888 \nL 92.336197 124.516178 \nL 98.458454 124.144725 \nL 104.580711 123.327527 \nL 110.702968 122.064585 \nL 116.825225 120.355898 \nL 122.947482 118.201468 \nL 129.069739 115.601293 \nL 135.191996 112.555374 \nL 141.314254 109.06371 \nL 147.436511 105.126302 \nL 153.558768 100.74315 \nL 159.681025 95.914254 \nL 165.803282 90.639614 \nL 171.925539 84.919229 \nL 178.047796 78.7531 \nL 184.170053 72.141226 \nL 190.29231 65.083608 \nL 196.414567 57.580247 \nL 202.536824 49.63114 \nL 208.659081 41.23629 \nL 214.781338 32.395695 \nL 220.903595 23.109356 \nL 227.025852 13.377273 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p7e2f94367c)\" d=\"M 49.480398 136.922727 \nL 55.602655 135.436913 \nL 61.724912 133.951099 \nL 67.847169 132.465285 \nL 73.969426 130.97947 \nL 80.091683 129.493656 \nL 86.21394 128.007842 \nL 92.336197 126.522028 \nL 98.458454 125.036213 \nL 104.580711 123.550399 \nL 110.702968 122.064585 \nL 116.825225 120.578771 \nL 122.947482 119.092956 \nL 129.069739 117.607142 \nL 135.191996 116.121328 \nL 141.314254 114.635514 \nL 147.436511 113.149699 \nL 153.558768 111.663885 \nL 159.681025 110.178071 \nL 165.803282 108.692257 \nL 171.925539 107.206442 \nL 178.047796 105.720628 \nL 184.170053 104.234814 \nL 190.29231 102.749 \nL 196.414567 101.263185 \nL 202.536824 99.777371 \nL 208.659081 98.291557 \nL 214.781338 96.805743 \nL 220.903595 95.319928 \nL 227.025852 93.834114 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 143.1 \nL 40.603125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 235.903125 143.1 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 143.1 \nL 235.903125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 7.2 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 47.603125 44.55625 \nL 168.975 44.55625 \nQ 170.975 44.55625 170.975 42.55625 \nL 170.975 14.2 \nQ 170.975 12.2 168.975 12.2 \nL 47.603125 12.2 \nQ 45.603125 12.2 45.603125 14.2 \nL 45.603125 42.55625 \nQ 45.603125 44.55625 47.603125 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 49.603125 20.298437 \nL 69.603125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_10\">\n     <!-- f(x) -->\n     <g transform=\"translate(77.603125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 49.603125 34.976562 \nL 69.603125 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_11\">\n     <!-- Tangent line(x=1) -->\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n     </defs>\n     <g transform=\"translate(77.603125 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"44.583984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"105.863281\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"169.242188\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"232.71875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"294.242188\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"357.621094\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"396.830078\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"428.617188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"456.400391\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"484.183594\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"547.5625\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"609.085938\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"648.099609\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"707.279297\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"791.068359\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"854.691406\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7e2f94367c\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"40.603125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "LGmUR4oedKwd",
        "outputId": "af6d8ad1-ebce-42c3-d183-a17ab46ae4b3"
      },
      "source": [
        "plot(x,[x**3-1/x,4*x-4],'x','f(x)',legend=['f(x)','Tangent line(x=1)'])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 251.909047 180.65625\" width=\"251.909047pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 180.65625 \nL 251.909047 180.65625 \nL 251.909047 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 48.982813 143.1 \nL 244.282813 143.1 \nL 244.282813 7.2 \nL 48.982813 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 57.860085 143.1 \nL 57.860085 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7f757efb66\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"57.860085\" xlink:href=\"#m7f757efb66\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(54.678835 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 119.082656 143.1 \nL 119.082656 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.082656\" xlink:href=\"#m7f757efb66\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(115.901406 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 180.305226 143.1 \nL 180.305226 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.305226\" xlink:href=\"#m7f757efb66\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(177.123976 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 241.527797 143.1 \nL 241.527797 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.527797\" xlink:href=\"#m7f757efb66\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(238.346547 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- x -->\n     <defs>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n     </defs>\n     <g transform=\"translate(143.673438 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 48.982813 136.926356 \nL 244.282813 136.926356 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"ma4a70d7198\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#ma4a70d7198\" y=\"136.926356\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- −10 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n      </defs>\n      <g transform=\"translate(20.878125 140.725575)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 48.982813 100.635539 \nL 244.282813 100.635539 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#ma4a70d7198\" y=\"100.635539\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(35.620313 104.434758)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 48.982813 64.344722 \nL 244.282813 64.344722 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#ma4a70d7198\" y=\"64.344722\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(29.257813 68.143941)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pb968899887)\" d=\"M 48.982813 28.053905 \nL 244.282813 28.053905 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.982813\" xlink:href=\"#ma4a70d7198\" y=\"28.053905\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(29.257813 31.853124)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- f(x) -->\n     <defs>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(14.798438 83.771094)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pb968899887)\" d=\"M 63.982342 136.922727 \nL 70.104599 118.751915 \nL 76.226856 112.634493 \nL 82.349113 109.475982 \nL 88.47137 107.440067 \nL 94.593628 105.900127 \nL 100.715885 104.575167 \nL 106.838142 103.313802 \nL 112.960399 102.022252 \nL 119.082656 100.635539 \nL 125.204913 99.104397 \nL 131.32717 97.388721 \nL 137.449427 95.454048 \nL 143.571684 93.26954 \nL 149.693941 90.806776 \nL 155.816198 88.038997 \nL 161.938455 84.940615 \nL 168.060712 81.486891 \nL 174.182969 77.653711 \nL 180.305226 73.417426 \nL 186.427483 68.754748 \nL 192.54974 63.64266 \nL 198.671997 58.058364 \nL 204.794255 51.979231 \nL 210.916512 45.38277 \nL 217.038769 38.2466 \nL 223.161026 30.548428 \nL 229.283283 22.266038 \nL 235.40554 13.377273 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pb968899887)\" d=\"M 57.860085 115.151866 \nL 63.982342 113.700233 \nL 70.104599 112.248601 \nL 76.226856 110.796968 \nL 82.349113 109.345335 \nL 88.47137 107.893703 \nL 94.593628 106.44207 \nL 100.715885 104.990437 \nL 106.838142 103.538805 \nL 112.960399 102.087172 \nL 119.082656 100.635539 \nL 125.204913 99.183907 \nL 131.32717 97.732274 \nL 137.449427 96.280641 \nL 143.571684 94.829008 \nL 149.693941 93.377376 \nL 155.816198 91.925743 \nL 161.938455 90.47411 \nL 168.060712 89.022478 \nL 174.182969 87.570845 \nL 180.305226 86.119212 \nL 186.427483 84.66758 \nL 192.54974 83.215947 \nL 198.671997 81.764314 \nL 204.794255 80.312682 \nL 210.916512 78.861049 \nL 217.038769 77.409416 \nL 223.161026 75.957784 \nL 229.283283 74.506151 \nL 235.40554 73.054518 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 48.982813 143.1 \nL 48.982813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.282813 143.1 \nL 244.282813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 48.982813 143.1 \nL 244.282813 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 48.982813 7.2 \nL 244.282813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 55.982813 44.55625 \nL 177.354688 44.55625 \nQ 179.354688 44.55625 179.354688 42.55625 \nL 179.354688 14.2 \nQ 179.354688 12.2 177.354688 12.2 \nL 55.982813 12.2 \nQ 53.982813 12.2 53.982813 14.2 \nL 53.982813 42.55625 \nQ 53.982813 44.55625 55.982813 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 57.982813 20.298437 \nL 77.982813 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_11\">\n     <!-- f(x) -->\n     <g transform=\"translate(85.982813 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 57.982813 34.976562 \nL 77.982813 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_22\"/>\n    <g id=\"text_12\">\n     <!-- Tangent line(x=1) -->\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n     </defs>\n     <g transform=\"translate(85.982813 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"44.583984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"105.863281\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"169.242188\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"232.71875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"294.242188\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"357.621094\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"396.830078\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"428.617188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"456.400391\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"484.183594\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"547.5625\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"609.085938\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"648.099609\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"707.279297\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"791.068359\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"854.691406\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb968899887\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"48.982813\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88k2tU0yeQ7x"
      },
      "source": [
        "# 自动求导\n",
        "> 我们可以通过深度学习框架自动计算导数,例如，我们想对y=2x转置x关于列向量x求导。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7Gkw7gYeVMf",
        "outputId": "faa0d154-c85e-4ae5-eefe-7c7bd3915d64"
      },
      "source": [
        "import torch\n",
        "x = torch.arange(4.0)\n",
        "x"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UANzxpY4fP3R"
      },
      "source": [
        "x.requires_grad_(True)   #在计算y关于x的梯度之前，我们需要一个地方来存储梯度，但他不会每次都重新分配内存，等价于x = torch.arange(4.0,requires_grad=True)\n",
        "x.grad   #默认是None"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIn4Fkn9gina",
        "outputId": "45645ab1-f8f0-41b0-f0bc-cdcfea427f62"
      },
      "source": [
        "y = 2 * torch.dot(x, x)   #y是个标量\n",
        "y"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74CngZjQg75M",
        "outputId": "adbf3a47-c3ea-4488-ac2c-6d9a816ff366"
      },
      "source": [
        "y.backward()    #我们可以通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。这些梯度会积累，下次算的时候记得清零\n",
        "x.grad"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKH2Yc3yia4t",
        "outputId": "f4e0edc2-1c0c-4ec9-a91e-a7628fbfb573"
      },
      "source": [
        "x.grad == 4 * x   #y=2x转置x的梯度应该是4x，验证一下！ "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DDzt11Aj0Hu",
        "outputId": "64d5d9c1-2235-45cd-f04d-f6561170dc86"
      },
      "source": [
        "x.T * x == x * x"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6XtQmoKkXTw",
        "outputId": "3b999c4d-2d09-4589-adce-f065bb5dc55c"
      },
      "source": [
        "#在算另一个函数我们要把梯度清零\n",
        "x.grad.zero_()\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzl6vETTk-J3",
        "outputId": "1c0af200-2077-46f9-d3e2-c28fe2582773"
      },
      "source": [
        "#非标量变量的反向传播，y不是标量。y关于向量x的导数最自然的解释是一个矩阵，也可以是高阶张量\n",
        "#对于非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度，在例子中，我们只想求偏导数的和，所以传递一个1的梯度是合适的\n",
        "x.grad.zero_()\n",
        "y = x * x\n",
        "#等价于y.backward(torch.ones(len(x)))\n",
        "y.sum().backward()\n",
        "x.grad"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}